# -*- coding: utf-8 -*-
"""SistemRekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z5G3pw3c-fa56_rN7NeueNCRKIs1hao4
"""

from google.colab import files
files.upload()
!ls -lha kaggle.json
!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d gargmanas/movierecommenderdataset

!unzip movierecommenderdataset.zip

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS

"""# Data Understanding"""

movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

"""Data terbagi menjadi dua bagian, yaitu: 
- Movies: berisi daftar film beserta genre nya. Terdapat pada file movies.csv
- Ratings: berisi daftar ID user, ID film dan rating yang diberikan oleh user. Terdapat pada file ratings.csb  
"""

print('jumlah data movies:   ', len(movies.movieId.unique()))
print('Jumlah data penilaian yang diberikan pengguna: ', len(ratings.userId.unique()))
print('Jumlah data penilaian movies: ', len(ratings.movieId.unique()))

"""## Movies"""

movies.head()

"""Variabel-variabel pada Movies Recommendations dataset pada file movies.csv adalah sebagai berikut:
- Movieid : id dari Movies.
- title : nama dari Movies.
- genres : genre dari Movies yang dipisahkan oleh vertical bar( | ).
"""

movies.info()

"""Berdasarkan output diatas, didapatkan informasi bahwa:
- tipe data dari kolom movieId yaitu int64, sedangkan tipe data dari kolom title dan genres yaitu object 
- jumlah data film atau movies yang ada pada dataset yaitu 9742 film.

## Ratings
"""

ratings.head()

ratings.info()

"""Variabel-variabel pada Movies Recommendations dataset pada file movies.csv adalah sebagai berikut:
- movieId : id dari Movies.
- userId : id dari user
- rating : rating yang diberikan user kepada film.
- timestamp : tanggal saat user memberikan rating tersebut
"""

ratings.shape

ratings.describe()

print('Jumlah user yang memberikan rating: ', len(ratings.userId.unique()))
print('Jumlah movies yang medapatkan rating dari user: ', len(ratings.movieId.unique()))
print('Jumlah data ratings: ', len(ratings))

"""Berdasarkan output diatas, didapatkan informasi bahwa:
- tipe data dari kolom movieId, userId dan timestamp yaitu int64, sedangkan tipe data dari kolom rating yaitu float64 
- jumlah data user yang memberikan rating yaitu 610 orang
- jumlah data film yang mendapatkan rating dari user yaitu 9724 film
- jumlah total rating yaitu 100836
- rating yang diberikan user berkisar antara 0.5 hingga 5
- sepertinya kolom timespace tidak akan berpengaruh pada hasil model nantinya, sehingga akan dihapus
"""

ratings = ratings.drop(['timestamp'], axis=1)
ratings

"""# Exploratory Data Analysis

## Movies
"""

movies.isnull().sum()

duplicate_rows_movies = movies[movies.duplicated()]
print("number of duplicate rows: ", duplicate_rows_movies.shape)

genres = movies.genres
stopwords = set(STOPWORDS)
comment_words = ''
for genre in genres:
 
    genre = str(genre)
    # split the different genres
    tokens = genre.split()
     
    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()
     
    comment_words += " ".join(tokens)+" "
wordcloud = WordCloud(width = 2000, height = 1000, background_color ='black', stopwords = stopwords, min_font_size = 10).generate(comment_words)
    
#Plot the wordcloud
plt.figure(figsize = (13, 10), facecolor = None)
plt.imshow(wordcloud)
plt.title("All Genre")
plt.axis("off")
plt.tight_layout(pad = 0)
plt.show()

"""Berdasarkan output diatas, didapatkan informasi bahwa:
- tidak terdapat nilai null ataupun duplikat pada dataset movies
- genre yang paling banyak muncul pada dataset movies diantaranya yaitu comedy, romance, drama, sci-fi

## Ratings
"""

ratings.isnull().sum()

duplicate_rows_ratings = ratings[ratings.duplicated()]
print("number of duplicate rows: ", duplicate_rows_ratings.shape)

sns.countplot(ratings.rating)

"""Berdasarkan output diatas, didapatkan informasi bahwa:
- tidak terdapat nilai null atau duplikat pada dataset ratings
- rating terbanyak yang diberikan oleh user yaitu 4,0 dan disusul oleh rating 3,0. 
- rating tersedikit yang diberikan oleh user yaitu 0,5.

# Data Preparation

Pada tahap Data preparation data akan disiapkan sebelum melakukan modelling.Adapun persiapan yang dilakukan yaitu:
- *merge* dataset movies dengan dataset ratings, 
- pengecekan missing value pada dataframe hasil *merge* 
- mengurutkan dataframe sesuai dengan id dari movie
- Membuang file yang duplikat.
- Mengonversi data menjadi list.
- membuat dictionary dataframe.
- Membuang stopwords pada dataframe.

Hal yang akan dilakukan pertama yaitu melakukan *merge* atau menggabungkan dataset movies dengan dataset ratings. Kodenya yaitu sebagai berikut.
"""

new_movie = pd.merge(movies, ratings , on='movieId', how='left')
new_movie

"""Selanjutnya, dilakukan pengecekan missing value pada dataframe hasil *merge* tadi"""

new_movie.isnull().sum()

"""berdasarkan output diatas, terdapat missing value pada dataframe baru yaitu new_movie, selanjutnya akan dihilangkan baris yang memiliki missing value tsb."""

new_movie = new_movie.dropna()
new_movie

new_movie.isnull().sum()

"""berdasarkan output diatas, dataframe new_movie telah bebas dari missing value. Selanjutnya akan diurutkan baris pada dataframe berdasarkan movieId."""

new_movie = new_movie.sort_values('movieId', ascending=True)
new_movie

"""Hal selanjutnya yaitu melihat apakah ada duplikasi pada movieId pada *dataframe* baru yang telah di *merge* sebelumnya."""

duplicate_rows_new_movie = new_movie[new_movie['movieId'].duplicated()]
print("number of duplicate rows: ", duplicate_rows_new_movie.shape)

"""Berdasarkan output diatas, terdapat nilai duplikasi pada dataframe baru, selanjunya yaitu akan kita hapus nilai duplikat tersebut dan dimasukkan kedalam variabel preparation."""

preparation = new_movie.drop_duplicates('movieId')

"""Hal selanjutnya yaitu menbuat dataframe movie_new yang berisi movie_id, movie_title dan movie_genre. Dataframe ini akan digunakan untuk menampilkan hasil rekomendasi menggunakan kedua jenis, yaitu content based dan collaborative."""

movie_id = preparation['movieId'].tolist()
 
movie_title = preparation['title'].tolist()
 
movie_genre = preparation['genres'].tolist()
 
print(len(movie_id))
print(len(movie_title))
print(len(movie_genre))

movie_new = pd.DataFrame({
    'Id': movie_id,
    'Title': movie_title,
    'Genre': movie_genre
})
movie_new

"""Hal selanjutnya yaitu menbuat *dataframe* data dan membuat fungsi sanitize yang akan digunakan dalam proses *removing stop word*  atau *text cleaning*."""

data = movie_new

def sanitize(x):
  try:
    if isinstance(x,list):
      return [i.replace(' ', ',').replace('|', ' ').replace('-','').lower() for i in x]  
    else:
      return [x.replace(' ','').lower()]
  except:
    print(x)

for i in data.Genre:
  data.Genre = data.Genre.apply(sanitize)

data.Genre

"""# **Model Developing**: Content Based Filtering

Algoritma Content Based Filtering adalah sistem yang merekomendasikan item yang mirip dengan item yang disukai pengguna di masa lalu.  Algoritma ini bekerja dengan menyarankan item serupa yang pernah disukai di masa lalu atau sedang dilihat di masa kini kepada pengguna. Semakin banyak informasi yang diberikan pengguna, semakin baik akurasi sistem rekomendasi. Kelebihan model ini yaitu sistem dapat merekomendasikan secara akurat item/film yang sesuai dengan user setelah user menonton film yang berkaitan dengan semakin banyaknya sample maka tingkat akurasinya akan sangat tinggi. Kelemahan dari sistem ini yaitu terbatasnya rekomendasi hanya terhadap item-item yang mirip sehingga tidak ada kesempatan untuk mendapatkan item yang tidak terduga.

Hal yang akan dilakukan pertama yaitu proses untuk menemukan representasi fitur penting dari setiap genre film menggunakan TF-IDF Vectorizer dari library sklearn. Kodenya yaitu sebagai berikut.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre
tf.fit(data['Genre'].astype(str)) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

"""Selanjutnya, dilakukan proses fit dan transformasi hasil sebelumnya ke dalam bentuk vektor. """

# Melakukan fit lalu ditransformasikan ke bentuk vektor
tfidf_matrix = tf.fit_transform(data['Genre'].astype(str)) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""lalu, lakukan proses todense untuk mengubah vektor tf-idf dalam bentuk matriks."""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Selanjutnya, buat dataframe baru untuk melihat hasil matriks tf-idf terhadap judul film dan beberapa genrenya."""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre
# Baris diisi dengan judul film
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.Title
).sample(20, axis=1).sample(10, axis=0)

"""Berdasarkan output diatas, didapatkan informasi bahwa film **Feds (1988)** merupakan film dengan genre comedy, dibuktikan dengan nilai tf-idf yaitu 1. Terdapat pula film **Dear John (2010)** merupakan film dengan genre war, romance dan drama.

Langkah selanjutnya yaitu menghitung derajat kesamaan (*similarity degree*) antar film dengan teknik cosine similarity dari library sklearn. Kodenya yaitu sebagai berikut. 
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Selanjutnya, buat dataframe untuk melihat matriks kesamaan setiap film. Kodenya yaitu sebagai berikut."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul film
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Title'], columns=data['Title'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap movie
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Berdasarkan informasi diatas, terdapat film yang memiliki nilai cosine similarity paling tinggi, yaitu film **Out Cold (2001)** dan film **Berlin Calling (2000)** dengan nilai cosine similarity sekitar 0.7. 

Selanjutnya, definikasn fungsi movie_recommendation untuk mendapatkan rekomendasi film berdasarkan user yang telah memberikan rating film sebelumnya. Ambil contoh si A telah memberikan rating yang bagus untuk film **Men In Black**, maka A akan mendapatkan rekomendasi film yang mirip dengan film **Men In Black** berdasarkan kesamaan yang dihitung dengan cosine similarity pada tahap sebelumnya
"""

def movie_recommendations(judul_film, similarity_data=cosine_sim_df, items=data[['Title', 'Genre']], k=7):
    """
    Rekomendasi movies berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    judul_film : tipe data string (str)
                judul film (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan film sebagai 
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
 
 
    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,judul_film].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop judul film agar judul film yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(judul_film, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Selanjutnya, terapkan kode untuk menemukan rekomendasi film yang mirip dengan film **Frequency (2000)**. """

data[data.Title.eq('Frequency (2000)')]

"""Berdasarkan output diatas, didapatkan informasi bahwa Film **Frequency (2000)** ternyata merupakan film dengan genre drama dan thriller.

Terakhir, kita jalankan fungsi movie_recommendations untuk mendapatkan rekomendasi film **Frequency (2000)**.
"""

# Mendapatkan rekomendasi film yang mirip dengan Frequency
movie_recommendations('Frequency (2000)')

"""Seperti yang dilihat pada output diatas, sistem berhasil memberikan rekomendasi film yang mirip dengan film **Frequency (2000)** menggunakan algoritma *content based filtering*. Mari lanjutkan ke algoritma selanjutnya yaitu *collaborative filtering*.

# **Model Developing**: *Collaborative Filtering*

Algoritma *Collaborative Filtering* adalah Algoritma yang bergantung pada pendapat komunitas pengguna. Ia tidak memerlukan atribut untuk setiap itemnya seperti pada algoritma sebelumnya. *Collaborative filtering* dibagi lagi menjadi dua kategori, yaitu: *model based* (metode berbasis model ML) dan *memory based* (metode berbasis memori). Kelebihan algoritma ini yaitu rekomendasi tetap akan berkerja dalam keadaan dimana konten sulit dianalisi sekalipun sedangkan kekurangannya yaitu membutuhkan parameter rating, sehingga jika ada item baru sistem tidak akan merekomendasikan item tersebut.

Hal yang akan dilakukan pertama kali untuk menerapkan algoritma ini yaitu mendefinisikan variabel df yang mengambil dari dataset ratings.csv yang telah melewati proses EDA.
"""

# Membaca dataset
 
df = ratings
df

"""Langkah selanjutnya yaitu cek beberapa hal dalam data seperti jumlah user, jumlah film, mengubah nilai rating menjadi float32 ."""

# Mendapatkan jumlah user
num_users = len(df.userId.unique())
print(num_users)
 
# Mendapatkan jumlah movie
num_movie = len(df.movieId.unique())
print(num_movie)
 
# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)
 
# Nilai minimum rating
min_rating = min(df['rating'])
 
# Nilai maksimal rating
max_rating = max(df['rating'])
 
print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Langkah berikutnya yaitu acak dataset terlebih dahulu agar distribusinya menjadi random dan lakukan split dataset menjadi data training dan data testing."""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value
x = df[['userId', 'movieId']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""Selanjutnya, buat class RecommenderNet dengan keras Model class. Kode class RecommenderNet ini terinspirasi dari tutorial dalam situs Keras dengan beberapa adaptasi sesuai kasus yang sedang kita selesaikan. Terapkan kode berikut."""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movie
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movie bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, lakukan proses compile terhadap model menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation. ."""

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Langkah selanjutnya, mulailah proses training. """

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 512,
    epochs = 50,
    validation_data = (x_val, y_val)
)

"""Langkah berikutnya, visualisasikan proses training dengan library matplotlib. Terapkan kode berikut."""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Berdasarkan informasi diatas, proses training telah dilakukan dengan cukup baik. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.19 dan error pada data validasi sekitar 0.23 Nilai tersebut cukup bagus untuk sistem rekomendasi.

Selanjutnya yaitu ambil sampel user secara acak dan definisikan variabel movie_not_view yang merupakan daftar film yang belum pernah dilihat oleh user. Kodenya yaitu sebagai berikut.
"""

movie_df = movie_new
df = pd.read_csv('ratings.csv')
 
# Mengambil sample user
user_id = df['userId'].sample(1).iloc[0]
movie_view_by_user = df[df['userId'] == user_id]
 
movie_not_view = movie_df[~movie_df['Id'].isin(movie_view_by_user.movieId.values)]['Id'] 
movie_not_view = list(
    set(movie_not_view)
    .intersection(set(df.movieId.keys()))
)
 
movie_not_view = [[df.movieId.get(x)] for x in movie_not_view]
user_encoder = df.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_view), movie_not_view)
)
user_movie_array = np.asarray(user_movie_array).astype(np.float32)

"""Selanjutnya, untuk memperoleh rekomendasi film, gunakan fungsi model.predict() dari library Keras dengan menerapkan kode berikut."""

ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    df.movieId.get(movie_not_view[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)
 
top_movie_user = (
    movie_view_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movie_df[movie_df['Id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.Title, ':', row.Genre)
 
print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)
 
recommended_movie = movie_df[movie_df['Id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.Title, ':', row.Genre)

"""Berdasarkan output diatas, model yang dihasilkan bisa memberikan rekomendasi film dengan cukup bagus. Hal ini bisa dibuktikan dengan film yang diberikan oleh sistem cukup sesuai dengan genre film yang diberikan rating tinggi oleh user. 

Begitulah kedua model yang telah dibuat. Semoga kedua model yang telah dibuat ini bisa membantu pengguna untuk mendapatkan rekomendasi film yang diinginkan.
"""